Training lm from:  [PosixPath('/home/pczapla/workspace/ulmfit-multilingual/data/wiki/de-100/models/sp15k/qrnn_nl4.m/lm_best'), PosixPath('/home/pczapla/workspace/ulmfit-multilingual/data/wiki/de-100/models/sp15k/qrnn_nl4.m/../itos')]
epoch     train_loss  valid_loss  accuracy
1         3.467852    2.558666    0.525457
Total time: 02:25
epoch     train_loss  valid_loss  accuracy
1         2.722157    2.387366    0.548566
2         2.477095    2.170018    0.580988
3         2.182971    1.981363    0.609205
4         2.078041    1.836848    0.629900
5         1.975613    1.744062    0.642769
6         1.866875    1.656678    0.655799
7         1.831995    1.595655    0.665479
8         1.768020    1.540487    0.673880
9         1.751569    1.488140    0.682557
10        1.647143    1.441723    0.690275
11        1.712795    1.399652    0.697534
12        1.529405    1.350384    0.706170
13        1.549134    1.313349    0.713210
14        1.585015    1.278395    0.719908
15        1.475010    1.248854    0.725591
16        1.532636    1.221373    0.731053
17        1.445181    1.203350    0.734503
18        1.396236    1.191440    0.737102
19        1.316587    1.186497    0.738052
20        1.374460    1.185027    0.738290
Total time: 1:11:26
/home/pczapla/workspace/ulmfit-multilingual/data/mldoc/de-1/models/sp15k
Saving info /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/de-1/models/sp15k/qrnn_nl4.m/info.json
Saving models at /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/de-1/models/sp15k/qrnn_nl4.m
Loss and accuracy using (cls_best): [1.3879647, tensor(0.2595)]
Processing data/wiki/en-100/models/sp15k/qrnn_nl4.m


------




$ python -m ulmfit eval --glob="wiki/*-100/models/sp15k/qrnn_nl4.m" --name nl4 --dataset-template='../mldoc/${lang}-1' --num-lm-epochs=20  --num-cls-epochs=8  --bs=18 --lr_sched=1cycle

First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁the', '▁,', 's', '▁.', '▁of', '▁and', '▁in', '▁to', '▁a', 'ed']
Training args:  {'clip': 0.12, 'alpha': 2, 'beta': 1, 'drop_mult': 0.3} dps:  {'output_p': 0.25, 'hidden_p': 0.1, 'input_p': 0.2, 'embed_p': 0.02, 'weight_p': 0.15}
Loading pretrained model
Unknown tokens 0, first 100: []
Training lm from:  [PosixPath('/home/pczapla/workspace/ulmfit-multilingual/data/wiki/en-100/models/sp15k/qrnn_nl4.m/lm_best'), PosixPath('/home/pczapla/workspace/ulmfit-multilingual/data/wiki/en-100/models/sp15k/qrnn_nl4.m/../itos')]
epoch     train_loss  valid_loss  accuracy
1         4.567319    3.820788    0.346054
Total time: 02:26
epoch     train_loss  valid_loss  accuracy
1         3.889761    3.601505    0.374049
2         3.570620    3.357854    0.406134
3         3.389516    3.153452    0.432199
4         3.217872    2.985234    0.452187
5         3.063675    2.851744    0.468071
6         3.023959    2.754062    0.480278
7         2.907327    2.647027    0.493494
8         2.786187    2.562560    0.505051
9         2.737610    2.500068    0.513554
10        2.696695    2.430095    0.523029
11        2.658439    2.380829    0.530339
12        2.598193    2.318927    0.539454
13        2.558214    2.275014    0.546136
14        2.520342    2.230543    0.553176
15        2.475964    2.190341    0.559245
16        2.370359    2.161100    0.564223
17        2.430078    2.136685    0.568197
18        2.383946    2.125458    0.569950
19        2.389433    2.117541    0.571265
20        2.297921    2.116168    0.571367
Total time: 1:11:10
/home/pczapla/workspace/ulmfit-multilingual/data/mldoc/en-1/models/sp15k
Saving info /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/en-1/models/sp15k/qrnn_nl4.m/info.json
Single training schedule
epoch     train_loss  valid_loss  accuracy
1         0.705876    0.241169    0.918000
2         0.450546    0.239528    0.926000
3         0.335179    0.221836    0.931000
4         0.202048    0.208652    0.951000
5         0.144956    0.223669    0.954000
6         0.073117    0.277062    0.953000
7         0.045186    0.258046    0.962000
8         0.022987    0.265977    0.961000
Total time: 02:33
Saving models at /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/en-1/models/sp15k/qrnn_nl4.m
Loss and accuracy using (cls_best): [0.29402012, tensor(0.9460)]
Processing data/wiki/es-100/models/sp15k/qrnn_nl4.m
../mldoc/es-1
Max vocab: 15000
Cache dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/es-1/models/sp15k
Model dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/es-1/models/sp15k/qrnn_nl4.m
Evaluating previously trained model
Loading validation /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/es-1/es.dev.csv
Data lm, trn: 13013, val: 1445
Data cls, trn: 1000, val: 1000
Data tst, trn: 1000, val: 4000
Size of vocabulary: 15000
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁de', '▁,', '▁la', '▁.', 's', '▁en', '▁el', '▁y', '▁a', '▁que']
Loss and accuracy using (cls_last): [0.19222946, tensor(0.9515)]
Processing data/wiki/fr-100/models/sp15k/qrnn_nl4.m
../mldoc/fr-1
Max vocab: 15000
Cache dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/fr-1/models/sp15k
Model dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/fr-1/models/sp15k/qrnn_nl4.m
Training
Loading validation /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/fr-1/fr.dev.csv
Running tokenization lm...
Data lm, trn: 13500, val: 1500
Running tokenization cls...
Data cls, trn: 1000, val: 1000
Running tokenization tst...
Data tst, trn: 1000, val: 4000
Size of vocabulary: 15000
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁de', '▁,', 's', '▁.', "'", '▁la', '▁le', '▁et', '▁l', '▁à']
Training args:  {'clip': 0.12, 'alpha': 2, 'beta': 1, 'drop_mult': 0.3} dps:  {'output_p': 0.25, 'hidden_p': 0.1, 'input_p': 0.2, 'embed_p': 0.02, 'weight_p': 0.15}
Loading pretrained model
Unknown tokens 0, first 100: []
Training lm from:  [PosixPath('/home/pczapla/workspace/ulmfit-multilingual/data/wiki/fr-100/models/sp15k/qrnn_nl4.m/lm_best'), PosixPath('/home/pczapla/workspace/ulmfit-multilingual/data/wiki/fr-100/models/sp15k/qrnn_nl4.m/../itos')]
epoch     train_loss  valid_loss  accuracy
1         3.375679    2.676224    0.454405
Total time: 02:19
epoch     train_loss  valid_loss  accuracy
1         2.901917    2.540690    0.475910
2         2.593614    2.370477    0.504601
3         2.423170    2.205713    0.530328
4         2.287688    2.083261    0.549087
5         2.161118    1.984955    0.564804
6         2.221017    1.912810    0.575434
7         2.111272    1.837854    0.588076
8         2.032289    1.775163    0.598341
9         1.984161    1.720519    0.607980
10        1.904775    1.668184    0.617407
11        1.829098    1.621347    0.626292
12        1.855409    1.577870    0.634512
13        1.843696    1.536835    0.642584
14        1.767968    1.496428    0.650317
15        1.741591    1.463305    0.656908
16        1.682118    1.438706    0.662601
17        1.666425    1.418383    0.666283
18        1.623713    1.406877    0.668710
19        1.645482    1.401546    0.669716
20        1.579352    1.399608    0.670167
Total time: 1:06:50
/home/pczapla/workspace/ulmfit-multilingual/data/mldoc/fr-1/models/sp15k
Saving info /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/fr-1/models/sp15k/qrnn_nl4.m/info.json
Single training schedule
epoch     train_loss  valid_loss  accuracy
1         0.614734    0.262120    0.906000
2         0.377443    0.327852    0.917000
3         0.296728    0.392655    0.903000
4         0.179866    0.423420    0.928000
5         0.114529    0.398973    0.935000
6         0.082004    0.325470    0.944000
7         0.047604    0.359636    0.945000
8         0.032579    0.354014    0.944000
Total time: 02:22
Saving models at /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/fr-1/models/sp15k/qrnn_nl4.m
Loss and accuracy using (cls_best): [0.33020702, tensor(0.9450)]
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁、', '▁。', '▁の', '▁に', '▁を', '▁年', 'の', '▁は', '▁・', '▁)']
Training args:  {'clip': 0.12, 'alpha': 2, 'beta': 1, 'drop_mult': 0.3} dps:  {'output_p': 0.25, 'hidden_p': 0.1, 'input_p': 0.2, 'embed_p': 0.02, 'weight_p': 0.15}
Loading pretrained model
Unknown tokens 0, first 100: []
Training lm from:  [PosixPath('/home/pczapla/workspace/ulmfit-multilingual/data/wiki/ja-100/models/sp15k/qrnn_nl4.m/lm_best'), PosixPath('/home/pczapla/workspace/ulmfit-multilingual/data/wiki/ja-100/models/sp15k/qrnn_nl4.m/../itos')]
epoch     train_loss  valid_loss  accuracy
1         3.524609    2.582580    0.512131
Total time: 02:34
epoch     train_loss  valid_loss  accuracy
1         2.656181    2.315530    0.550262
2         2.265949    2.019140    0.598469
3         1.985897    1.769565    0.638234
4         1.831071    1.617888    0.660760
5         1.735492    1.509642    0.677379
6         1.637924    1.427618    0.690664
7         1.564483    1.363384    0.700825
8         1.508054    1.318165    0.708210
9         1.471599    1.267787    0.716080
10        1.398376    1.232899    0.722340
11        1.311976    1.199602    0.728811
12        1.401354    1.162299    0.735328
13        1.385588    1.132408    0.740850
14        1.256193    1.106556    0.745935
15        1.289892    1.083529    0.750840
16        1.220951    1.063360    0.754845
17        1.259715    1.050884    0.757371
18        1.165468    1.042870    0.759241
19        1.242660    1.038160    0.760036
20        1.194239    1.037506    0.760167
Total time: 1:13:55
/home/pczapla/workspace/ulmfit-multilingual/data/mldoc/ja-1/models/sp15k
Saving info /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/ja-1/models/sp15k/qrnn_nl4.m/info.json
Single training schedule
epoch     train_loss  valid_loss  accuracy
1         0.760780    0.391838    0.872000
2         0.592674    0.427392    0.870000
3         0.446265    0.593488    0.838000
4         0.318780    0.605533    0.858000
5         0.226914    0.665538    0.872000
6         0.135525    0.742310    0.891000
7         0.063984    0.778616    0.892000
8         0.039366    0.827663    0.884000
Total time: 02:49
Saving models at /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/ja-1/models/sp15k/qrnn_nl4.m
Loss and accuracy using (cls_best): [0.70555997, tensor(0.8960)]
Processing data/wiki/zh-100/models/sp15k/qrnn_nl4.m
../mldoc/zh-1
Max vocab: 15000
Cache dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/zh-1/models/sp15k
Model dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/zh-1/models/sp15k/qrnn_nl4.m
Evaluating previously trained model
Loading validation /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/zh-1/zh.dev.csv
Data lm, trn: 13500, val: 1500
Data cls, trn: 1000, val: 1000
Data tst, trn: 1000, val: 4000
Size of vocabulary: 15000
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁,', '▁的', '▁。', '▁年', '▁、', '▁在', '▁一', '▁是', '▁中', '▁有']
Loss and accuracy using (cls_last): [0.30052844, tensor(0.8982)]
OrderedDict([('data/mldoc/de-1/models/sp15k/qrnn_nl4.m', 0.2592499852180481),
             ('data/mldoc/en-1/models/sp15k/qrnn_nl4.m', 0.9462500214576721),
             ('data/mldoc/es-1/models/sp15k/qrnn_nl4.m', 0.9514999985694885),
             ('data/mldoc/fr-1/models/sp15k/qrnn_nl4.m', 0.9442499876022339),
             ('data/mldoc/ja-1/models/sp15k/qrnn_nl4.m', 0.8960000276565552),
             ('data/mldoc/zh-1/models/sp15k/qrnn_nl4.m', 0.8982499837875366)])








                       !! WARNING !!

  warnings.warn(ABI_INCOMPATIBILITY_WARNING.format(compiler))
Single training schedule
epoch     train_loss  valid_loss  accuracy
1         0.610785    0.239165    0.923000
2         0.392899    0.281254    0.937000
3         0.268695    0.444383    0.909000
4         0.162150    0.427744    0.931000
5         0.109248    0.422351    0.948000
6         0.061984    0.411351    0.947000
7         0.033645    0.413174    0.951000
8         0.018704    0.404264    0.947000
Total time: 02:16
Saving models at /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/de-1/models/sp15k/qrnn_nl4.m
Loss and accuracy using (cls_best): [0.29712877, tensor(0.9565)]
Processing data/wiki/en-100/models/sp15k/qrnn_nl4.m
../mldoc/en-1
Max vocab: 15000
Cache dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/en-1/models/sp15k
Model dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/en-1/models/sp15k/qrnn_nl4.m
Evaluating previously trained model
Loading validation /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/en-1/en.dev.csv
Data lm, trn: 13500, val: 1500
Data cls, trn: 1000, val: 1000
Data tst, trn: 1000, val: 4000
Size of vocabulary: 15000
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁the', '▁,', 's', '▁.', '▁of', '▁and', '▁in', '▁to', '▁a', 'ed']
Loss and accuracy using (cls_last): [0.29526812, tensor(0.9463)]
Processing data/wiki/es-100/models/sp15k/qrnn_nl4.m
../mldoc/es-1
Max vocab: 15000
Cache dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/es-1/models/sp15k
Model dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/es-1/models/sp15k/qrnn_nl4.m
Evaluating previously trained model
Loading validation /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/es-1/es.dev.csv
Data lm, trn: 13013, val: 1445
Data cls, trn: 1000, val: 1000
Data tst, trn: 1000, val: 4000
Size of vocabulary: 15000
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁de', '▁,', '▁la', '▁.', 's', '▁en', '▁el', '▁y', '▁a', '▁que']
Loss and accuracy using (cls_last): [0.19222946, tensor(0.9515)]
Processing data/wiki/fr-100/models/sp15k/qrnn_nl4.m
../mldoc/fr-1
Max vocab: 15000
Cache dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/fr-1/models/sp15k
Model dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/fr-1/models/sp15k/qrnn_nl4.m
Evaluating previously trained model
Loading validation /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/fr-1/fr.dev.csv
Data lm, trn: 13500, val: 1500
Data cls, trn: 1000, val: 1000
Data tst, trn: 1000, val: 4000
Size of vocabulary: 15000
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁de', '▁,', 's', '▁.', "'", '▁la', '▁le', '▁et', '▁l', '▁à']
Loss and accuracy using (cls_last): [0.33129737, tensor(0.9442)]
Processing data/wiki/it-100/models/sp15k/qrnn_nl4.m
../mldoc/it-1
Max vocab: 15000
Cache dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/it-1/models/sp15k
Model dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/it-1/models/sp15k/qrnn_nl4.m
Training
Loading validation /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/it-1/it.dev.csv
Running tokenization lm...
Data lm, trn: 13500, val: 1500
Running tokenization cls...
Data cls, trn: 1000, val: 1000
Running tokenization tst...
Data tst, trn: 1000, val: 4000
Size of vocabulary: 15000
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁,', '▁.', '▁di', '▁e', "▁&'", "'", '▁il', '▁la', '▁in', 'e']
Training args:  {'clip': 0.12, 'alpha': 2, 'beta': 1, 'drop_mult': 0.3} dps:  {'output_p': 0.25, 'hidden_p': 0.1, 'input_p': 0.2, 'embed_p': 0.02, 'weight_p': 0.15}
Loading pretrained model
Unknown tokens 0, first 100: []
Training lm from:  [PosixPath('/home/pczapla/workspace/ulmfit-multilingual/data/wiki/it-100/models/sp15k/qrnn_nl4.m/lm_best'), PosixPath('/home/pczapla/workspace/ulmfit-multilingual/data/wiki/it-100/models/sp15k/qrnn_nl4.m/../itos')]
epoch     train_loss  valid_loss  accuracy
1         3.929510    2.916437    0.434550
Total time: 01:20
epoch     train_loss  valid_loss  accuracy
1         3.231523    2.723415    0.461407
2         2.823881    2.498599    0.496812
3         2.586648    2.283846    0.530524
4         2.417038    2.125690    0.553137
5         2.278636    1.995558    0.572757
6         2.199877    1.887804    0.589102
7         2.090629    1.799082    0.603201
8         2.046975    1.725273    0.615247
9         1.935966    1.654829    0.626968
10        1.921190    1.590797    0.638228
11        1.894758    1.528087    0.649369
12        1.792718    1.477532    0.658754
13        1.679359    1.428426    0.668648
14        1.723383    1.377170    0.678987
15        1.597491    1.339658    0.686348
16        1.620966    1.307664    0.692993
17        1.568962    1.284500    0.697923
18        1.533934    1.271438    0.700628
19        1.496832    1.264714    0.701968
20        1.486198    1.262870    0.702333
Total time: 39:33
/home/pczapla/workspace/ulmfit-multilingual/data/mldoc/it-1/models/sp15k
Saving info /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/it-1/models/sp15k/qrnn_nl4.m/info.json
Single training schedule
epoch     train_loss  valid_loss  accuracy
1         0.784124    0.414312    0.847000
2         0.550873    0.413405    0.861000
3         0.445371    0.363693    0.877000
4         0.271702    0.426771    0.899000
5         0.165902    0.556069    0.881000
6         0.091403    0.628809    0.897000
7         0.065516    0.693292    0.893000
8         0.033616    0.675199    0.897000
Total time: 01:24
Saving models at /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/it-1/models/sp15k/qrnn_nl4.m
Loss and accuracy using (cls_best): [0.7380945, tensor(0.8992)]
Processing data/wiki/ja-100/models/sp15k/qrnn_nl4.m
../mldoc/ja-1
Max vocab: 15000
Cache dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/ja-1/models/sp15k
Model dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/ja-1/models/sp15k/qrnn_nl4.m
Evaluating previously trained model
Loading validation /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/ja-1/ja.dev.csv
Data lm, trn: 13500, val: 1500
Data cls, trn: 1000, val: 1000
Data tst, trn: 1000, val: 4000
Size of vocabulary: 15000
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁、', '▁。', '▁の', '▁に', '▁を', '▁年', 'の', '▁は', '▁・', '▁)']
Loss and accuracy using (cls_last): [0.7049702, tensor(0.8953)]
Processing data/wiki/zh-100/models/sp15k/qrnn_nl4.m
../mldoc/zh-1
Max vocab: 15000
Cache dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/zh-1/models/sp15k
Model dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/zh-1/models/sp15k/qrnn_nl4.m
Evaluating previously trained model
Loading validation /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/zh-1/zh.dev.csv
Data lm, trn: 13500, val: 1500
Data cls, trn: 1000, val: 1000
Data tst, trn: 1000, val: 4000
Size of vocabulary: 15000
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁,', '▁的', '▁。', '▁年', '▁、', '▁在', '▁一', '▁是', '▁中', '▁有']
Loss and accuracy using (cls_last): [0.30052844, tensor(0.8982)]
OrderedDict([('data/mldoc/de-1/models/sp15k/qrnn_nl4.m', 0.9564999938011169),
             ('data/mldoc/en-1/models/sp15k/qrnn_nl4.m', 0.9462500214576721),
             ('data/mldoc/es-1/models/sp15k/qrnn_nl4.m', 0.9514999985694885),
             ('data/mldoc/fr-1/models/sp15k/qrnn_nl4.m', 0.9442499876022339),
             ('data/mldoc/it-1/models/sp15k/qrnn_nl4.m', 0.8992499709129333),
             ('data/mldoc/ja-1/models/sp15k/qrnn_nl4.m', 0.8952500224113464),
             ('data/mldoc/zh-1/models/sp15k/qrnn_nl4.m', 0.8982499837875366)])






## DE
----------------------------------------
Training issues


1/2nd -- That was without fine tuning !!! 0 shot:)
```
python -m ulmfit load_cls data/mldoc/de-1/models/sp15k/qrnn_nl4.m  --lang=de - train 0 --num-cls-epochs 8 --bs=18 --lr-sched=1cycle                                             ✘ 1
Max vocab: 15000
Cache dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/de-1/models/sp15k
Model dir: /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/de-1/models/sp15k/qrnn_None.m
Loading validation /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/de-1/de.dev.csv
Data lm, trn: 13500, val: 1500
Data cls, trn: 1000, val: 1000
Data tst, trn: 1000, val: 4000
Size of vocabulary: 15000
First 20 words in vocab: ['xxunk', 'xxpad', 'xxbos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', '<unk>', '▁', '▁.', '▁,', '▁der', '▁die', 'en', '▁und', 's', '▁in', 'er', "▁&'"]
/home/pczapla/anaconda3/envs/fastaiv1/lib/python3.7/site-packages/torch/utils/cpp_extension.py:152: UserWarning:

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler (c++) may be ABI-incompatible with PyTorch!
Please use a compiler that is ABI-compatible with GCC 4.9 and above.
See https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html.

See https://gist.github.com/goldsborough/d466f43e8ffc948ff92de7486c5216d6
for instructions on how to install GCC 4.9 or higher.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

  warnings.warn(ABI_INCOMPATIBILITY_WARNING.format(compiler))
Single training schedule
epoch     train_loss  valid_loss  accuracy
1         1.310368    1.177105    0.520000
2         1.096284    0.899281    0.739000
3         0.860910    0.668378    0.864000
4         0.676764    0.733304    0.868000
5         0.573360    0.590983    0.885000
6         0.438448    0.446631    0.918000
7         0.397323    0.531330    0.919000
8         0.339557    0.437841    0.922000
Total time: 02:25
Saving models at /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/de-1/models/sp15k/qrnn_None.m
Loss and accuracy using (cls_best): [0.3380329, tensor(0.9295)]
0.33803290128707886
0.9294999837875366
```

3rd aproach
```
Single training schedule
epoch     train_loss  valid_loss  accuracy
1         0.610785    0.239165    0.923000
2         0.392899    0.281254    0.937000
3         0.268695    0.444383    0.909000
4         0.162150    0.427744    0.931000
5         0.109248    0.422351    0.948000
6         0.061984    0.411351    0.947000
7         0.033645    0.413174    0.951000
8         0.018704    0.404264    0.947000
Total time: 02:16
Saving models at /home/pczapla/workspace/ulmfit-multilingual/data/mldoc/de-1/models/sp15k/qrnn_nl4.m
Loss and accuracy using (cls_best): [0.29712877, tensor(0.9565)]
```